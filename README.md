# Helena-Repository
Welcome to My GitHub Repository!

This repository contains a collection of projects that I have worked on. Each project is organized into its own directory along with any relevant documentation, code, and resources. Feel free to explore and provide feedback!

# TOUR GUIDE ROBOT (May 2025 - Present)
 Undergraduate Reasearcher at the University of Michigan Autonomous Vehicle Research Intergroup Collaboration ([MAVRIC]([url](https://mavric.si.umich.edu/home))) Lab:**

Purpose of the study aims to investigate the effects of our mixed-agent team on user satisfaction and learning performance in robot-guided tour scenarios, and to design a new metric, called Following, based on observable human behaviors. The results of this study can enhance the quality of real-world interactions between humans and robots.  
 
- Collaborated in a research team to develop a tour guide robot system measuring human-robot following behaviors
- Developed real-time software modules in ROS Noetic to integrate and process multi-sensor data streams on the Toyota Human Support Robot (HSR)
- Implemented algorithms in Python for multi-camera ArUco marker detection and precise localization of human subjects
- Engineered and optimized PID control loops to dynamically orient the robot head, ensuring continuous human-robot interaction
- Integrated an additional Intel RealSense D435i camera to improve perception accuracy by enhancing environmental sensing capabilities
- Built flexible testing environments to conduct user studies, driving iterative improvements based on empirical data

Below are some images of my contributions:<br>

Robot projecting virtual avatar during tour session:<br>
<img width="509" height="662" alt="Screenshot 2025-08-22 at 4 40 08 PM" src="https://github.com/user-attachments/assets/59caac8c-e485-4115-b980-16ed2094ae46" />

Point Cloud Reconstruction in Open3D:<br>
<img width="578" height="318" alt="Screenshot 2025-08-22 at 4 44 00 PM" src="https://github.com/user-attachments/assets/909f2355-df14-47c3-bfff-a68b929edc6d" />


# HUMAN VISUAL PERSPECTIVE TAKING ESTIMATION (August 2024 - May 2025)
Undergraduate Reasearcher at the University of Michigan Autonomous Vehicle Research Intergroup Collaboration ([MAVRIC]([url](https://mavric.si.umich.edu/home))) Lab:**
https://sites.google.com/view/umich-urop2024-25-engagement/setting-nvida-isaac

This project explores the question: How can robots estimate human visual perspective (VPT) using only common onboard sensors?
  
- Visual Perspective Taking (VPT) is the ability to understand another person’s viewpoint, taking into account what they see and how they see it.
- Developed a novel multi-modal VPT extraction algorithm that integrates:
  - Visual SLAM (VSLAM) to build a 3D map of the environment
  - RGB-D sensor data to track human head and gaze positions in real-time
  
  Features
  - Real-time human head and gaze tracking
  - Integration with RGB-D cameras (e.g. Intel RealSense)
  - SLAM-based scene reconstruction using RTAB-Map
  - ROS-compatible architecture
  - Open3D-based rendering and visual output
  - Output visualization in RViz and ROS image topics

<img width="684" alt="Screenshot 2025-06-08 at 2 02 51 PM" src="https://github.com/user-attachments/assets/9fc4ad04-928c-46e5-a01a-88d8830fc96f" />


# ROB 102 (Fall 2024): Introduction to AI and Programming:
Below are some of the projects that I worked on in this class. These projects range from driving in a star to wall following to developing a breadth first search path planning algorithm.

**Project 1 Wall Follower Checkpoint Videos**
- [Drive Square Demo](https://drive.google.com/file/d/1tMW7yRODxny66sLa-o42Muot1w4mKYjA/view?usp=sharing)
- [Follow Me 1D Demo](https://drive.google.com/file/d/1LWufWUzry9QBVPiw17irv8JxUTdeV4BC/view?usp=sharing)
- [Drive Star Demo](https://drive.google.com/file/d/1qEvuWSZ3VkWlhqoXxU7Be2pLKbptl9lT/view?usp=sharing)
- [Follow Me 2D Demo](https://drive.google.com/file/d/1-6NgjZ3PY8BDyGQ-sMeC_WCJ1zHDHbSd/view?usp=drive_link)
- [Wall Follower Demo](https://drive.google.com/file/d/1SdfmCH3lXhFtj_JmQFho2R_S6ZB3bOaO/view?usp=sharing)

**Project 2 Bug Navigation Checkpoint Videos**
- [Robot Hits the Spot Demo](https://drive.google.com/file/d/1KOR-LOGgDojt7m0uWE1eUbCL8nmE_8x8/view?usp=sharing)
- [Bug Navigation Demo](https://drive.google.com/file/d/1i5BkDj3tiplTPPgzpDKMhSkoJJNv6JMl/view?usp=sharing)


# EECS 280 Fall (2025): Programming and Introductory Data Structures
https://eecs280.org/

This repository contains the programming projects I completed as part of the EECS 280 (Foundations of Computer Science and Programming) course at the University of Michigan. EECS 280 is a second-semester foundational programming course that focuses on essential computer science concepts and programming skills using C++.

Throughout the course, I worked on a series of projects to deepen my understanding of various topics, including data structures, algorithms, recursion, and object-oriented programming. The course emphasized writing correct and maintainable code, testing, and debugging skills, and the use of C++ language features such as classes, templates, and exceptions.

**Projects Included:**
- Statistics Tool - Implemented a two-sample statistical analysis tool.
- Computer Vision - Developed an image resizing algorithm without distortion. 
- Euchre Game - Simulated the Euchre card game, a popular game in Michigan. 
- Machine Learning - Built a tool to automatically categorize EECS 280 forum posts.
- Text Editor - Created a terminal-based text editor with interactive file manipulation.
- Binary Search Tree - Implemented a map using a binary search tree.

**Key Skills Developed:**
- Linked lists, stacks, queues, binary trees.
- Recursion & Functional Abstraction.
- Data Abstraction, Inheritance, Polymorphism.
- Dynamic resource management and memory handling in C++.
- Testing, debugging, and writing maintainable code.
